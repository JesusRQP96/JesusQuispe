{
  "hash": "c58b9cc5ac25ee3c8dba26646330b71d",
  "result": {
    "markdown": "---\ntitle: \"Analisis Cluster \"\nsubtitle: \" Cluster jerarquico \"\ndescription: |\n  Applicacion del cluster\ndate: \"2025-06-01\"\ncategories: [Cluster analysis,Multivariate Analysis]\nexecute:\n  message: false\n  warning: false\n---\n\n\n# Analisis de cluster\n\n-   objetivo: los objetos/elementos del mismo cluster sean lo mas parecido entre ellos y los elementos entre clusters sean los mas diferentes posibles.\n\n-   Metodos clasicos de clustering se pueden clasificar en 2 tipos :\n\n    -   Procedimiento de cluster jerarquico.\n    -   Procedimiento de cluster no jerarquico.\n\n-   Metodos jerarquicos requieren una matriz de distancia/ disimilaridad, esta matriz se puede calcular de diversas formas,tipicamente se usa una medida de distancia que esta implementada en las funciones de R y se denonima la distancia euclediana.\n\n## Metodos/ algoritmos de Cluster jerarquico\n\n-   Destaca el metodo de *Clusters agloremativo* : El algoritmo caracteristico es AGNES (aggloramerative nesting), este es bottom-up, cada registro es una hoja, los cuales se van juntando en un nuevo cluster, hasta forma un solo cluster de todos los registros.\n\n## Cluster jerarquico en la practica (with R )\n\n### Preparacion de la bd\n\n-   los registros corresponden a los individuos y las columnas a las variables de segmentacion\n-   todos los datos missing deben ser o removidos o estimados de algun modo\n-   todas las variables han de ser escaladas, osea han de tener media = 0, desv. standar = 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# Indiviudos como observaciones y campos como variables de segmentacion\n\ndf           <-   readRDS(\"bd_world_health_indicators.rds\")  # cada registro es un pais \n\nset.seed(135)                                       # Establecer la semilla\ndf           <- df[sample(nrow(df), size = 98), ]\n\n\nView(df)\n\n\n# Elimina missing values\ndf           <-   na.omit(df)\nrownames(df) <- df$Country\n\ndf           <- df %>% select_if(is.numeric)\n\n\n\n# estandarizacion\ndf.std       <-  scale(df)\n```\n:::\n\n\n### Cluster jerarquico aglomerativo\n\n#### Creacion de matriz de disimilaridad\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Matriz de disimilaridad \n# El primer paso es crear la matriz de disimilidaria es decir la matriz de distancias\n#  \nd   <- dist(df, method=\"euclidean\")\n\n# Grafico una muestra de 5 datos para visualizar la matriz de distancia\nas.matrix(d)[1:5,1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    Afghanistan Antigua and Barbuda   Bolivia     Kuwait\nAfghanistan             0.00000            8290.348  8390.612   73.06278\nAntigua and Barbuda  8290.34839               0.000 16677.256 8290.64358\nBolivia              8390.61214           16677.256     0.000 8394.02412\nKuwait                 73.06278            8290.644  8394.024    0.00000\nJapan                 405.08014            7995.014  8705.635  360.09107\n                        Japan\nAfghanistan          405.0801\nAntigua and Barbuda 7995.0138\nBolivia             8705.6347\nKuwait               360.0911\nJapan                  0.0000\n```\n:::\n:::\n\n\n#### Ejecucion de cluster jerarquico\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##  con complete linkage\nhc1 <- hclust(d, method = \"complete\" )\n```\n:::\n\n\n#### Grafico de dendograma preliminar\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dendextend)         # mas herramientas para objetos dendgroam\nlibrary(circlize)           # los cuales tienen por funcion por defecto\n\ndd <- as.dendrogram(hc1)    # funcion nativa, para tranforma la data a clase dedrograma\n                            # ideal para el grafico\n\ndd                                    %>% \ncirclize_dendrogram(dend_track_height = 0.5,\n                    facing = \"inside\")\n```\n\n::: {.cell-output-display}\n![](analysis_clusters_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### Determinar el numero optimo de clusters\n\nUna vez ejecutado el algoritmo de clusterizacion, se visualiza varios clusters, por lo que el siguiente paso es detectar cual seria el numero de clusters ideal (K)\n\n#### Métodos directos\n\n::: panel-tabset\n##### Elbow method\n\n-   El objetivo es correr el algoritmo de cluster para distintos numeros de clusters (k) y proceder al calculo del within sum of square(WSS), la idea seleccionar el numero de clusters a partir del cual escoger un cluster más no mejora la suma de cuadrados\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"factoextra\")\nlibrary(factoextra)\n\ndf                                              %>% \nfviz_nbclust(FUN = hcut, method = \"wss\")\n```\n\n::: {.cell-output-display}\n![](analysis_clusters_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n-   el metodo \"elbow\" sugiere que el numero optimo son 4 clusters\n\n##### Average silhoutte Method\n\n-   Indican cuan bien cada elemento de un cluster esta dentro de su cluster\n\n-   Un ancho (width) de silueta mayor indica un buen proceso de clusterizacion\n\n-   El numero optimo de clusters (k), es igual a aquel que maximiza el promedio de la silueta sobre un rango posible de valores de K.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf                                              %>% \nfviz_nbclust(FUN = hcut, method = \"silhouette\")\n```\n\n::: {.cell-output-display}\n![](analysis_clusters_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n-   El metodo de silueta sugiere que 4 son el numero optimo de clusters a realizar.\n:::\n\n#### Método de testeo estadistico\n\n##### Metodo de estadistico GAP\n\n-   el estadistico garp mide la dispersion dentro de cada Cluster comparada con una distribucion uniforme de valores.\n\n-   mas alto el estadistico Gap mas diferente de una distribucion uniforme es la distribucion interna de los datos en los clusters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cluster)\n\ngap_stat <- df                                                              %>% \n            cluster::clusGap( FUN = hcut, nstart = 25, K.max = 10, B = 50)\n\nfviz_gap_stat(gap_stat)\n```\n\n::: {.cell-output-display}\n![](analysis_clusters_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n-   Este metodo sugiere que 6 son los clusters necesarios .\n\n### Creacion de Clusters\n\nSe establecieron de 4 a 6 clusters, procedemos a asignar cada registro a un cluster determinado\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclts_grps_4 <- cutree(hc1, k = 4)\nlength(clts_grps_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 98\n```\n:::\n\n```{.r .cell-code}\nclts_grps_6 <- cutree(hc1, k = 6)\nlength(clts_grps_6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 98\n```\n:::\n:::\n\n\n### Validacion de clusters\n\nQueda claro que el numero de clusters optimo, es 4 o 6, por lo cual procedos a emplear metodos de validacion espaciales para clusters para detectar finalmente cual numero se ajusta mejor a los datos\n\n#### Validacion interna\n\n-   Un indice claro es el dunn index, el cual debe ser el maximizo posible\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fpc)\ncl_sts_4 <- cluster.stats(d = d, clts_grps_4)\ncl_sts_6 <- cluster.stats(d = d, clts_grps_6)\n\ncl_sts_4$dunn\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.859057\n```\n:::\n\n```{.r .cell-code}\ncl_sts_6$dunn\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.312669\n```\n:::\n:::\n\n\n-   Queda claro que 4 clusters es el numero ideal de clusters\n\n#### Cluster final\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualiazacion del cluster jerarquico \n\nfactoextra::fviz_cluster(list(data = df, \n                              cluster = clts_grps_4),\n                          ellipse.type = \"norm\",\n                          geom = \"point\",\n                          palette = \"jco\",\n                         ggtheme = theme_minimal())\n```\n\n::: {.cell-output-display}\n![](analysis_clusters_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "analysis_clusters_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}