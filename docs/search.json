[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a Economist (PUCP). I worked in research and the insurance sector. I blog about statistics, programming, and data analytics applied in quantitative finance, actuarial science or economics.\nI have extensive experience with causal inference, regression analysis, spatial analysis, econometrics, actuarial analytics.\nI excel at applied statistics, especially developing new methods to analyze complex data sets.\nI love to collaborate with scientists and product teams on involved projects.\nYou can find my resume here. I’m currently based in Lima,Peru"
  },
  {
    "objectID": "Articles/2019-05-10_Beauty_ggplots/2019-05-10_Beauty_ggplots.html",
    "href": "Articles/2019-05-10_Beauty_ggplots/2019-05-10_Beauty_ggplots.html",
    "title": "Plotting with Ggplot2:Barplot",
    "section": "",
    "text": "Plot beauty barplots\nWe had data of admissions to UCB\n\n\n\n\n\nAdmit\nGender\nDept\nFreq\n\n\n\n\nAdmitted\nMale\nA\n512\n\n\nRejected\nMale\nA\n313\n\n\nAdmitted\nFemale\nA\n89\n\n\nRejected\nFemale\nA\n19\n\n\nAdmitted\nMale\nB\n353\n\n\nRejected\nMale\nB\n207\n\n\nAdmitted\nFemale\nB\n17\n\n\nRejected\nFemale\nB\n8\n\n\nAdmitted\nMale\nC\n120\n\n\nRejected\nMale\nC\n205\n\n\nAdmitted\nFemale\nC\n202\n\n\nRejected\nFemale\nC\n391\n\n\nAdmitted\nMale\nD\n138\n\n\nRejected\nMale\nD\n279\n\n\nAdmitted\nFemale\nD\n131\n\n\nRejected\nFemale\nD\n244\n\n\nAdmitted\nMale\nE\n53\n\n\nRejected\nMale\nE\n138\n\n\nAdmitted\nFemale\nE\n94\n\n\nRejected\nFemale\nE\n299\n\n\nAdmitted\nMale\nF\n22\n\n\nRejected\nMale\nF\n351\n\n\nAdmitted\nFemale\nF\n24\n\n\nRejected\nFemale\nF\n317\n\n\n\n\n\nA first approach\n\n\n\n\n\nPlot upgraded"
  },
  {
    "objectID": "Articles/2022-01-10_Time_series/Time_series.html",
    "href": "Articles/2022-01-10_Time_series/Time_series.html",
    "title": "Plotting with Ggplot2:Time series",
    "section": "",
    "text": "Plotting Time series with ggplot\n#Packages\n\nLoad Data\n\n\nplot"
  },
  {
    "objectID": "Articles.html",
    "href": "Articles.html",
    "title": "Articles",
    "section": "",
    "text": "Plotting with Ggplot2:Time series\n\n\nTime series\n\n\n\n\n\n\n\n\n\nJan 10, 2022\n\n\n2 min\n\n\n\n\n\n\n\n\nAprendizaje automatico usando Tidymodels\n\n\nMachine learning & Quantitative finance\n\n\n\n\n\n\n\n\n\nJun 10, 2021\n\n\n8 min\n\n\n\n\n\n\n\n\nPlotting with Ggplot2:Barplot\n\n\nBarplot\n\n\n\n\n\n\n\n\n\nMay 10, 2019\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jesus Quispe Q.",
    "section": "",
    "text": "Page of Jesus Miguel Quispe Quispe"
  },
  {
    "objectID": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html",
    "href": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html",
    "title": "Aprendizaje automatico usando Tidymodels",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\n\n\n\n\nUno de los modelos clasicos para llevar acabo el pricing de opciones es el modelo black-sholes el cual tipicamente plantea la siguiente entidad :\n\\[ C(S_0,t) = S_0 N(d_1) - Ke^{-r(T-t)}N(d_2)\\]\nDonde:\n\n\\(S_0\\): Precio del subyacente (Stock Price)\n\\(C(S0,t)\\): Price of the Call Option\n\\(K\\): Exercise Price\n\\((T−t)\\): Tiempo de maduracion, donde T es la fecha de ejercicio(Time to Maturity, where T is Exercise Date)\n\\(σ\\): Volatilidad subyacente (Underlying Volatility (a standard deviation of log returns))\n\\(r\\): Tasa de interes libre de riesgo (Risk-free Interest Rate (i.e., T-bill Rate))\n\nEsta ecuacion puede ser formulada en R del siguiente modo :\n\nblack_scholes_price &lt;- function(S, K = 70, r = 0, T = 1, sigma = 0.2) {\n  \n  d1     &lt;- (log(S / K) + (r + sigma^2 / 2) * T) / (sigma * sqrt(T))\n  d2     &lt;-  d1 - sigma * sqrt(T)\n  price  &lt;-  S * pnorm(d1) - K * exp(-r * T) * pnorm(d2)\n  \n  return(price)\n}\n\nEmpleando la anterior expresion, podemos simular precios de opciones;asi como una base de datos de sus determinantes. Dado lo anterior, tendremos un escenario perfecto para llevar acabo metodologias asociadas al aprendizaje automatico o ML ya que podriamos calcular el predecir el precio de una opcion financiera . Asi partimos simulando la base de datos necesaria para el problema de regresion que se nos presenta\n\nset.seed(420)\n\noption_prices &lt;- expand_grid(\n  S = 40:50,\n  K = 20:40,\n  r = seq(from = 0, to = 0.03, by = 0.01),\n  T = seq(from = 3 / 12, to = 1.5, by = 1 / 12),\n  sigma = seq(from = 0.1, to = 0.3, by = 0.1)\n) |&gt;\n  mutate(\n    black_scholes = black_scholes_price(S, K, r, T, sigma),\n    observed_price = map_dbl(\n      black_scholes,\n      function(x) x + rnorm(1, sd = 0.15)\n    )\n  )\n\ndata.table::data.table(option_prices)\n\n        S  K    r         T sigma black_scholes observed_price\n    1: 40 20 0.00 0.2500000   0.1      20.00000       20.04016\n    2: 40 20 0.00 0.2500000   0.2      20.00000       19.85949\n    3: 40 20 0.00 0.2500000   0.3      20.00000       20.08943\n    4: 40 20 0.00 0.3333333   0.1      20.00000       19.95319\n    5: 40 20 0.00 0.3333333   0.2      20.00000       20.05970\n   ---                                                        \n44348: 50 40 0.03 1.4166667   0.2      12.35408       12.35424\n44349: 50 40 0.03 1.4166667   0.3      13.71750       13.80824\n44350: 50 40 0.03 1.5000000   0.1      11.78703       11.99148\n44351: 50 40 0.03 1.5000000   0.2      12.49918       12.77917\n44352: 50 40 0.03 1.5000000   0.3      13.92104       13.94021\n\n\nInmediatamente procedemos a establecer el conjunto de datos de entrenamiento y testeo. Asi como establecemos la metodologia de V-fold validacion cruzada sobre el conjunto de datos de entrenamiento\n\n# 40 -60% \nsplit         &lt;- initial_split(option_prices, prop = 0.40)\noption_train  &lt;- training(split)\noption_test   &lt;- testing(split)\n\n\n\n\nset.seed(123)\noption_folds &lt;- vfold_cv(option_train, v = 20)\n\n\n\n\nLuego procedemos a plantear los potenciales predictores del precio de la opcion; asi como el procesamiento basico de los mismo o Feature engineering .Para ello empleamos una ‘recipe’\n\nrec.option &lt;- recipe(observed_price ~ .,\n              data = option_prices\n              ) |&gt;\n  step_rm(black_scholes) |&gt;\n  step_normalize(all_predictors())\n\n\n\n\nDefinimos el set de modelos que emplearemos y evaluaremos su performance\n\nmars_model &lt;- mars(  num_terms = tune(),\n                       prod_degree = tune(),\n                       prune_method = tune())  |&gt;\n                set_engine(\"earth\")            |&gt;\n                set_mode(\"regression\")\n\n\nlibrary(bonsai)\nrf_model &lt;-   rand_forest(mtry  = tune(), \n                           min_n  = tune(), trees = 100)            |&gt;\n              set_engine(\"ranger\")    |&gt;\n              set_mode(\"regression\")\n\n\n\n\nlgbm_model &lt;-   boost_tree(learn_rate = tune(), stop_iter = tune(),\n                            trees = 100) %&gt;%\n                set_engine(\"lightgbm\", num_leaves = tune()) %&gt;%\n                set_mode(\"regression\")\n\n\n\n\n\nmars_wflow   &lt;- workflow(rec.option, mars_model)\nrf_wflow     &lt;- workflow(rec.option, rf_model)\nlgbm_wflow   &lt;- workflow(rec.option, lgbm_model)\n\nLuego procedemos a ajustar el modelo planteado sobre los ‘folds’ creados, mediante la metodologia de validacion cruzada de manera que se busca optimizar los hiperparametros de los modelos planteados\n\nset.seed(123)\nmars_time_grid &lt;- system.time(\n                  mars_res_grid &lt;- tune_grid(mars_wflow, option_folds, grid = 5)\n)\n\n\nset.seed(123)\nrf_time_grid&lt;- system.time(\n                  rf_res_grid &lt;- tune_grid(rf_wflow, option_folds, grid = 5)\n)\n\n\nset.seed(123)\nlgbm_time_grid &lt;- system.time(\n                  lgbm_res_grid &lt;- tune_grid(lgbm_wflow, option_folds, grid = 5)\n)\n\n\n\n\nProcedemos a seleccionar el mejor modelo empleando para ello la metrica de error de la raiz cuadrada media estandarizada o rsme( por sus siglas en ingles )\n\nrf_rmse       &lt;- rf_res_grid %&gt;%\n                 select_best(\"rmse\", maximize = FALSE)\n\nlgbm_rmse     &lt;- lgbm_res_grid %&gt;%\n                 select_best(\"rmse\", maximize = FALSE)\n\nmars_rmse     &lt;- mars_res_grid %&gt;%\n                 select_best(\"rmse\", maximize = FALSE)\n\n\n\n\nfinal_mars &lt;- finalize_workflow(\n              mars_wflow,\n              mars_rmse\n)\n\nfinal_rf &lt;- finalize_workflow(\n              rf_wflow,\n              rf_rmse\n)\n\nfinal_lgbm &lt;- finalize_workflow(\n              lgbm_wflow,\n              lgbm_rmse\n)\n\n\n\nFinalmente reorganizamos los resultados de las metricas de error para facilitar la seleccion del mejor modelo.\n\nm_mars_db  &lt;- last_fit(\n              final_mars,\n              split\n              ) %&gt;%\n              collect_metrics() %&gt;% \n              mutate(.model =\"mars\")\n\n\nm_rf_db  &lt;- last_fit(\n            final_rf,\n            split\n            ) %&gt;%\n            collect_metrics() %&gt;% \n              mutate(.model =\"Random.Forest\")\n\nm_lgbm_db  &lt;- last_fit(\n              final_lgbm,\n              split\n              ) %&gt;%\n              collect_metrics()%&gt;% \n              mutate(.model =\"Light.gbm\")\n\n\nmtrcs_db   &lt;-rbind(m_mars_db,\n                   m_rf_db,\n                   m_lgbm_db)\n\n\n\n\n\n\n\n  \n    \n      Metricas de error\n    \n    \n      Pricing opciones\n    \n    \n      .model\n      rmse\n      rsq\n    \n  \n  \n    mars\n1.2432680\n0.9627034\n    Random.Forest\n0.2153714\n0.9988867\n    Light.gbm\n5.0747239\n0.9848114"
  },
  {
    "objectID": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#modelo-black--sholes",
    "href": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#modelo-black--sholes",
    "title": "Aprendizaje automatico usando Tidymodels",
    "section": "",
    "text": "Uno de los modelos clasicos para llevar acabo el pricing de opciones es el modelo black-sholes el cual tipicamente plantea la siguiente entidad :\n\\[ C(S_0,t) = S_0 N(d_1) - Ke^{-r(T-t)}N(d_2)\\]\nDonde:\n\n\\(S_0\\): Precio del subyacente (Stock Price)\n\\(C(S0,t)\\): Price of the Call Option\n\\(K\\): Exercise Price\n\\((T−t)\\): Tiempo de maduracion, donde T es la fecha de ejercicio(Time to Maturity, where T is Exercise Date)\n\\(σ\\): Volatilidad subyacente (Underlying Volatility (a standard deviation of log returns))\n\\(r\\): Tasa de interes libre de riesgo (Risk-free Interest Rate (i.e., T-bill Rate))\n\nEsta ecuacion puede ser formulada en R del siguiente modo :\n\nblack_scholes_price &lt;- function(S, K = 70, r = 0, T = 1, sigma = 0.2) {\n  \n  d1     &lt;- (log(S / K) + (r + sigma^2 / 2) * T) / (sigma * sqrt(T))\n  d2     &lt;-  d1 - sigma * sqrt(T)\n  price  &lt;-  S * pnorm(d1) - K * exp(-r * T) * pnorm(d2)\n  \n  return(price)\n}\n\nEmpleando la anterior expresion, podemos simular precios de opciones;asi como una base de datos de sus determinantes. Dado lo anterior, tendremos un escenario perfecto para llevar acabo metodologias asociadas al aprendizaje automatico o ML ya que podriamos calcular el predecir el precio de una opcion financiera . Asi partimos simulando la base de datos necesaria para el problema de regresion que se nos presenta\n\nset.seed(420)\n\noption_prices &lt;- expand_grid(\n  S = 40:50,\n  K = 20:40,\n  r = seq(from = 0, to = 0.03, by = 0.01),\n  T = seq(from = 3 / 12, to = 1.5, by = 1 / 12),\n  sigma = seq(from = 0.1, to = 0.3, by = 0.1)\n) |&gt;\n  mutate(\n    black_scholes = black_scholes_price(S, K, r, T, sigma),\n    observed_price = map_dbl(\n      black_scholes,\n      function(x) x + rnorm(1, sd = 0.15)\n    )\n  )\n\ndata.table::data.table(option_prices)\n\n        S  K    r         T sigma black_scholes observed_price\n    1: 40 20 0.00 0.2500000   0.1      20.00000       20.04016\n    2: 40 20 0.00 0.2500000   0.2      20.00000       19.85949\n    3: 40 20 0.00 0.2500000   0.3      20.00000       20.08943\n    4: 40 20 0.00 0.3333333   0.1      20.00000       19.95319\n    5: 40 20 0.00 0.3333333   0.2      20.00000       20.05970\n   ---                                                        \n44348: 50 40 0.03 1.4166667   0.2      12.35408       12.35424\n44349: 50 40 0.03 1.4166667   0.3      13.71750       13.80824\n44350: 50 40 0.03 1.5000000   0.1      11.78703       11.99148\n44351: 50 40 0.03 1.5000000   0.2      12.49918       12.77917\n44352: 50 40 0.03 1.5000000   0.3      13.92104       13.94021\n\n\nInmediatamente procedemos a establecer el conjunto de datos de entrenamiento y testeo. Asi como establecemos la metodologia de V-fold validacion cruzada sobre el conjunto de datos de entrenamiento\n\n# 40 -60% \nsplit         &lt;- initial_split(option_prices, prop = 0.40)\noption_train  &lt;- training(split)\noption_test   &lt;- testing(split)\n\n\n\n\nset.seed(123)\noption_folds &lt;- vfold_cv(option_train, v = 20)"
  },
  {
    "objectID": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#definicion-del-predictor",
    "href": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#definicion-del-predictor",
    "title": "Aprendizaje automatico usando Tidymodels",
    "section": "",
    "text": "Luego procedemos a plantear los potenciales predictores del precio de la opcion; asi como el procesamiento basico de los mismo o Feature engineering .Para ello empleamos una ‘recipe’\n\nrec.option &lt;- recipe(observed_price ~ .,\n              data = option_prices\n              ) |&gt;\n  step_rm(black_scholes) |&gt;\n  step_normalize(all_predictors())"
  },
  {
    "objectID": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#definicion-del-modelo-o-engine",
    "href": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#definicion-del-modelo-o-engine",
    "title": "Aprendizaje automatico usando Tidymodels",
    "section": "",
    "text": "Definimos el set de modelos que emplearemos y evaluaremos su performance\n\nmars_model &lt;- mars(  num_terms = tune(),\n                       prod_degree = tune(),\n                       prune_method = tune())  |&gt;\n                set_engine(\"earth\")            |&gt;\n                set_mode(\"regression\")\n\n\nlibrary(bonsai)\nrf_model &lt;-   rand_forest(mtry  = tune(), \n                           min_n  = tune(), trees = 100)            |&gt;\n              set_engine(\"ranger\")    |&gt;\n              set_mode(\"regression\")\n\n\n\n\nlgbm_model &lt;-   boost_tree(learn_rate = tune(), stop_iter = tune(),\n                            trees = 100) %&gt;%\n                set_engine(\"lightgbm\", num_leaves = tune()) %&gt;%\n                set_mode(\"regression\")"
  },
  {
    "objectID": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#definicion-de-los-flujos-de-trabajo",
    "href": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#definicion-de-los-flujos-de-trabajo",
    "title": "Aprendizaje automatico usando Tidymodels",
    "section": "",
    "text": "mars_wflow   &lt;- workflow(rec.option, mars_model)\nrf_wflow     &lt;- workflow(rec.option, rf_model)\nlgbm_wflow   &lt;- workflow(rec.option, lgbm_model)\n\nLuego procedemos a ajustar el modelo planteado sobre los ‘folds’ creados, mediante la metodologia de validacion cruzada de manera que se busca optimizar los hiperparametros de los modelos planteados\n\nset.seed(123)\nmars_time_grid &lt;- system.time(\n                  mars_res_grid &lt;- tune_grid(mars_wflow, option_folds, grid = 5)\n)\n\n\nset.seed(123)\nrf_time_grid&lt;- system.time(\n                  rf_res_grid &lt;- tune_grid(rf_wflow, option_folds, grid = 5)\n)\n\n\nset.seed(123)\nlgbm_time_grid &lt;- system.time(\n                  lgbm_res_grid &lt;- tune_grid(lgbm_wflow, option_folds, grid = 5)\n)"
  },
  {
    "objectID": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#mejor-modelo",
    "href": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#mejor-modelo",
    "title": "Aprendizaje automatico usando Tidymodels",
    "section": "",
    "text": "Procedemos a seleccionar el mejor modelo empleando para ello la metrica de error de la raiz cuadrada media estandarizada o rsme( por sus siglas en ingles )\n\nrf_rmse       &lt;- rf_res_grid %&gt;%\n                 select_best(\"rmse\", maximize = FALSE)\n\nlgbm_rmse     &lt;- lgbm_res_grid %&gt;%\n                 select_best(\"rmse\", maximize = FALSE)\n\nmars_rmse     &lt;- mars_res_grid %&gt;%\n                 select_best(\"rmse\", maximize = FALSE)\n\n\n\n\nfinal_mars &lt;- finalize_workflow(\n              mars_wflow,\n              mars_rmse\n)\n\nfinal_rf &lt;- finalize_workflow(\n              rf_wflow,\n              rf_rmse\n)\n\nfinal_lgbm &lt;- finalize_workflow(\n              lgbm_wflow,\n              lgbm_rmse\n)\n\n\n\nFinalmente reorganizamos los resultados de las metricas de error para facilitar la seleccion del mejor modelo.\n\nm_mars_db  &lt;- last_fit(\n              final_mars,\n              split\n              ) %&gt;%\n              collect_metrics() %&gt;% \n              mutate(.model =\"mars\")\n\n\nm_rf_db  &lt;- last_fit(\n            final_rf,\n            split\n            ) %&gt;%\n            collect_metrics() %&gt;% \n              mutate(.model =\"Random.Forest\")\n\nm_lgbm_db  &lt;- last_fit(\n              final_lgbm,\n              split\n              ) %&gt;%\n              collect_metrics()%&gt;% \n              mutate(.model =\"Light.gbm\")\n\n\nmtrcs_db   &lt;-rbind(m_mars_db,\n                   m_rf_db,\n                   m_lgbm_db)\n\n\n\n\n\n\n\n  \n    \n      Metricas de error\n    \n    \n      Pricing opciones\n    \n    \n      .model\n      rmse\n      rsq\n    \n  \n  \n    mars\n1.2432680\n0.9627034\n    Random.Forest\n0.2153714\n0.9988867\n    Light.gbm\n5.0747239\n0.9848114"
  },
  {
    "objectID": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#carga-de-paquetes",
    "href": "Articles/2021-06-10_ML_Options/2021-06-10_ML_Options.html#carga-de-paquetes",
    "title": "Aprendizaje automatico usando Tidymodels",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)"
  }
]